{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Pseudo-Label Generation\n",
    "\n",
    "This notebook utilizes the \"Teacher\" models trained in Stage 1 to perform inference on the unlabeled dataset (`UNLABELED_DIR`).\n",
    "\n",
    "**Methodology:**\n",
    "1. Load the best checkpoint for each selected Teacher architecture (e.g., ResNet18, ResNet50).\n",
    "2. Predict class probabilities for every unlabeled image.\n",
    "3. **Confidence Thresholding:** Only predictions exceeding the defined confidence threshold (`CONFIDENCE_THRESHOLD`) are accepted.\n",
    "4. Accepted images are copied into a new directory structure (`pseudo_labels/`), effectively expanding the training set for the \"Student\" model in the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: Imports & Setup\n",
    "# ==============================================================================\n",
    "import torch\n",
    "import shutil\n",
    "import models\n",
    "import utils\n",
    "import config\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Ensure reproducibility (optional but good practice for inference order)\n",
    "torch.manual_seed(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 3: Configuration of Models for Inference\n",
    "# ==============================================================================\n",
    "\n",
    "# Define which architectures to evaluate for pseudo-label generation.\n",
    "# Typically, we evaluate multiple teachers to decide which one generates the best quality dataset.\n",
    "TEACHER_MODELS_TO_USE = ['resnet18', 'resnet50'] \n",
    "\n",
    "# Confidence Threshold (High confidence required to avoid noise propagation)\n",
    "CONFIDENCE_THRESHOLD = 0.80\n",
    "\n",
    "print(f\"[CONFIG] Selected models for pseudo-labeling: {TEACHER_MODELS_TO_USE}\")\n",
    "print(f\"[CONFIG] Confidence Threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "\n",
    "# Verify Unlabeled Data Directory\n",
    "unlabeled_dir = config.UNLABELED_DIR\n",
    "if not unlabeled_dir.exists():\n",
    "    raise FileNotFoundError(f\"Unlabeled data directory not found at: {unlabeled_dir}\")\n",
    "\n",
    "# Retrieve list of images\n",
    "unlabeled_images = list(unlabeled_dir.glob(\"*.png\"))\n",
    "print(f\"[DATA] Total unlabeled images found: {len(unlabeled_images)}\")\n",
    "\n",
    "# Load class names from the training directory structure to ensure consistency\n",
    "class_names = sorted([p.name for p in config.TRAIN_VAL_DIR.iterdir() if p.is_dir()])\n",
    "print(f\"[DATA] Detected Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 4: Pseudo-Labeling Pipeline\n",
    "# ==============================================================================\n",
    "\n",
    "def find_best_teacher_checkpoint(model_arch):\n",
    "    \"\"\"\n",
    "    Locates the most recent training run for a given architecture \n",
    "    and returns the path to the 'best_model.pth' checkpoint.\n",
    "    \"\"\"\n",
    "    # Search in the artifacts directory defined in config.py\n",
    "    results_dir = config.ARTIFACTS_DIR\n",
    "    \n",
    "    # Filter directories matching the teacher pattern\n",
    "    candidates = sorted([d for d in results_dir.iterdir() if d.name.startswith(f\"teacher_{model_arch}\")])\n",
    "    \n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    # Select the most recent run (last in sorted list)\n",
    "    best_run = candidates[-1]\n",
    "    return best_run / \"best_model.pth\"\n",
    "\n",
    "device = torch.device(config.DEVICE)\n",
    "\n",
    "# --- Main Inference Loop ---\n",
    "for model_arch in TEACHER_MODELS_TO_USE:\n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"[INFO] PROCESSING MODEL: {model_arch.upper()}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    # 1. Locate Checkpoint\n",
    "    ckpt_path = find_best_teacher_checkpoint(model_arch)\n",
    "    if not ckpt_path or not ckpt_path.exists():\n",
    "        print(f\"[ERROR] Checkpoint not found for {model_arch}. Skipping...\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"[INFO] Loading weights from: {ckpt_path.name}\")\n",
    "    \n",
    "    # 2. Load Model Architecture\n",
    "    # Note: resnet_use_pretrain=False because we are loading our own fine-tuned weights\n",
    "    model = models.make_model(model_arch, len(class_names), resnet_use_pretrain=False)\n",
    "    \n",
    "    # Load state dictionary\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=device, weights_only=True))\n",
    "    except TypeError: \n",
    "        # Fallback for older PyTorch versions lacking weights_only\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "        \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 3. Prepare Output Directory\n",
    "    # We create a specific folder for each teacher model's pseudo-labels\n",
    "    output_dir = config.PSEUDO_LABEL_DIR / model_arch\n",
    "    \n",
    "    if output_dir.exists():\n",
    "        print(f\"[INFO] Cleaning existing output directory: {output_dir}\")\n",
    "        shutil.rmtree(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create subdirectories for each class\n",
    "    for cname in class_names:\n",
    "        (output_dir / cname).mkdir(exist_ok=True)\n",
    "        \n",
    "    # 4. Inference and File Sorting\n",
    "    accepted_count = 0\n",
    "    print(f\"[INFO] Generating pseudo-labels (Threshold >= {CONFIDENCE_THRESHOLD})...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_path in tqdm(unlabeled_images, desc=f\"Inference {model_arch}\"):\n",
    "            try:\n",
    "                # A. Load and Preprocess Image\n",
    "                img_tensor = utils.load_png_gray(img_path) \n",
    "                \n",
    "                # Resize if using ResNet backbone (matches training preprocessing)\n",
    "                if \"resnet\" in model_arch:\n",
    "                    img_tensor = torch.nn.functional.interpolate(\n",
    "                        img_tensor.unsqueeze(0), \n",
    "                        size=config.IMG_SIZE if hasattr(config, 'IMG_SIZE') else (100, 100), \n",
    "                        mode=\"bilinear\", \n",
    "                        align_corners=False\n",
    "                    ).squeeze(0)\n",
    "                \n",
    "                img_tensor = img_tensor.unsqueeze(0).to(device) # Add batch dimension\n",
    "                \n",
    "                # B. Forward Pass\n",
    "                logits = model(img_tensor)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                max_prob, pred_idx = torch.max(probs, dim=1)\n",
    "                \n",
    "                confidence = max_prob.item()\n",
    "                pred_class = class_names[pred_idx.item()]\n",
    "                \n",
    "                # C. Threshold Check\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                    # Copy file to the corresponding class folder\n",
    "                    dest_path = output_dir / pred_class / img_path.name\n",
    "                    shutil.copy(str(img_path), str(dest_path))\n",
    "                    accepted_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Failed to process {img_path.name}: {e}\")\n",
    "                \n",
    "    # 5. Final Report for this Model\n",
    "    acceptance_rate = accepted_count / len(unlabeled_images) if unlabeled_images else 0\n",
    "    print(f\"\\n[RESULT] {model_arch.upper()}: Accepted {accepted_count}/{len(unlabeled_images)} images ({acceptance_rate:.1%}).\")\n",
    "    print(f\"[INFO] Pseudo-labels saved to: {output_dir}\")\n",
    "\n",
    "print(\"\\n[DONE] Pseudo-labeling stage completed.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "from_bard": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
