{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f68f26c-f131-4c8f-8fdd-820434e64015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# --- EXPERIMENT CONFIGURATION ---\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# PATH CONFIGURATION (Relative Path)\n",
    "# Assuming the notebook runs from the root or 'notebooks' folder\n",
    "BASE_DATA_DIR = Path(\"data/experimento_baselines\") \n",
    "\n",
    "CARRIER_NAMES = [\n",
    "    \"Carrier_C1_675\",\n",
    "    \"Carrier_C2_2825\",\n",
    "    \"Carrier_C3_2975\",\n",
    "    \"Carrier_C4_9435\"\n",
    "]\n",
    "\n",
    "TRAIN_FOLDER_NAME = \"train_set_70\"\n",
    "TEST_FOLDER_NAME = \"test_set_15\"\n",
    "IMAGE_SIZE = (100, 100)\n",
    "\n",
    "# Suppress convergence warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def load_and_flatten_images(base_dir: Path) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Loads images from directory, converts to grayscale, resizes, \n",
    "    and flattens them into 1D vectors for Scikit-Learn models.\n",
    "    \"\"\"\n",
    "    X_data, y_data = [], []\n",
    "    \n",
    "    if not base_dir.exists():\n",
    "        print(f\"[ERROR] Path not found: {base_dir}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    # Get class names, ignoring specific non-class folders\n",
    "    classes = sorted([\n",
    "        d.name for d in base_dir.iterdir() \n",
    "        if d.is_dir() and d.name.upper() != \"SIN_CLASIFICAR\"\n",
    "    ])\n",
    "    \n",
    "    if not classes:\n",
    "        print(f\"[ERROR] No class directories found in {base_dir}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    print(f\"   > Loading data from: {base_dir.name}\")\n",
    "    print(f\"   > Detected classes: {classes}\")\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = base_dir / class_name\n",
    "        # Support multiple image formats\n",
    "        image_paths = list(class_dir.glob('*.png')) + \\\n",
    "                      list(class_dir.glob('*.jpg')) + \\\n",
    "                      list(class_dir.glob('*.jpeg'))\n",
    "        \n",
    "        if not image_paths:\n",
    "            print(f\"[WARN] Class '{class_name}' is empty.\")\n",
    "            continue\n",
    "\n",
    "        for img_path in tqdm(image_paths, desc=f\"Reading {class_name}\", leave=False, ncols=80):\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    # 1. Convert to Grayscale ('L')\n",
    "                    img = img.convert('L')\n",
    "                    # 2. Resize to fixed dimensions\n",
    "                    img = img.resize(IMAGE_SIZE)\n",
    "                    # 3. Flatten (100, 100) -> (10000,) vector\n",
    "                    img_vector = np.asarray(img).flatten()\n",
    "                    \n",
    "                    X_data.append(img_vector)\n",
    "                    y_data.append(class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed to read {img_path.name}: {e}\")\n",
    "\n",
    "    return np.array(X_data), np.array(y_data), classes\n",
    "\n",
    "def run_single_carrier(train_dir: Path, test_dir: Path) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Executes training and evaluation for a single carrier scenario.\n",
    "    Returns a dictionary containing F1-Macro scores for RF and SVM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load Data\n",
    "    X_train, y_train, _ = load_and_flatten_images(train_dir)\n",
    "    X_test, y_test, _ = load_and_flatten_images(test_dir)\n",
    "    \n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(\"[ERROR] Missing training or testing data. Skipping carrier.\")\n",
    "        return {\"rf_f1\": 0.0, \"svm_f1\": 0.0}\n",
    "\n",
    "    # 2. Feature Engineering (Standard Scaling)\n",
    "    print(\"   > Standardizing features (StandardScaler)...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Model A: Random Forest\n",
    "    print(\"   > Training Random Forest...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    y_pred_rf = rf.predict(X_test_scaled)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='macro', zero_division=0)\n",
    "    print(f\"     Result: RF F1-Macro: {f1_rf:.4f}\")\n",
    "\n",
    "    # 4. Model B: SVM (RBF Kernel)\n",
    "    print(\"   > Training SVM (RBF Kernel)...\")\n",
    "    svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=RANDOM_STATE)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred_svm = svm.predict(X_test_scaled)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='macro', zero_division=0)\n",
    "    print(f\"     Result: SVM F1-Macro: {f1_svm:.4f}\")\n",
    "\n",
    "    return {\"rf_f1\": f1_rf, \"svm_f1\": f1_svm}\n",
    "\n",
    "def main_experiment_loop():\n",
    "    \"\"\"\n",
    "    Main execution loop: Iterates through carriers, runs benchmarks, \n",
    "    and generates the final comparison table.\n",
    "    \"\"\"\n",
    "    print(\"-\" * 60)\n",
    "    print(\"STARTING EXPERIMENT 3.1: CLASSICAL BASELINES (SVM & RF)\")\n",
    "    print(f\"Base Data Path: {BASE_DATA_DIR}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if not BASE_DATA_DIR.exists():\n",
    "        print(f\"[CRITICAL] Data directory not found at: {BASE_DATA_DIR}\")\n",
    "        print(\"Please ensure your data folders are correctly placed.\")\n",
    "        return\n",
    "\n",
    "    # Dictionary to store results\n",
    "    all_results = {\n",
    "        \"SVM (RBF Kernel)\": [],\n",
    "        \"Random Forest (100 est.)\": []\n",
    "    }\n",
    "    \n",
    "    for carrier_name in CARRIER_NAMES:\n",
    "        print(f\"\\nProcessing: {carrier_name}\")\n",
    "        \n",
    "        train_path = BASE_DATA_DIR / carrier_name / TRAIN_FOLDER_NAME\n",
    "        test_path = BASE_DATA_DIR / carrier_name / TEST_FOLDER_NAME\n",
    "        \n",
    "        # Execute benchmark\n",
    "        scores = run_single_carrier(train_path, test_path)\n",
    "        \n",
    "        # Store results\n",
    "        all_results[\"SVM (RBF Kernel)\"].append(scores[\"svm_f1\"])\n",
    "        all_results[\"Random Forest (100 est.)\"].append(scores[\"rf_f1\"])\n",
    "\n",
    "    # --- Generate Final Table ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXPERIMENTS COMPLETED. GENERATING TABLE 10...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Calculate Averages\n",
    "    avg_svm = np.mean(all_results[\"SVM (RBF Kernel)\"])\n",
    "    avg_rf = np.mean(all_results[\"Random Forest (100 est.)\"])\n",
    "    \n",
    "    # Print Markdown Header\n",
    "    header = \"| Model |\"\n",
    "    divider = \"| :--- |\"\n",
    "    for name in CARRIER_NAMES:\n",
    "        # Extract carrier identifier (e.g., C1_675)\n",
    "        short_name = name.split('_', 1)[1] \n",
    "        header += f\" {short_name} |\"\n",
    "        divider += \" :---: |\"\n",
    "    header += \" Average |\"\n",
    "    divider += \" :---: |\"\n",
    "    print(header)\n",
    "    print(divider)\n",
    "\n",
    "    # Print SVM Row\n",
    "    svm_scores = all_results[\"SVM (RBF Kernel)\"]\n",
    "    svm_row = f\"| SVM (RBF Kernel) |\"\n",
    "    for score in svm_scores:\n",
    "        svm_row += f\" {score:.2f} |\"\n",
    "    svm_row += f\" **{avg_svm:.2f}** |\"\n",
    "    print(svm_row)\n",
    "\n",
    "    # Print RF Row\n",
    "    rf_scores = all_results[\"Random Forest (100 est.)\"]\n",
    "    rf_row = f\"| Random Forest (100 est.) |\"\n",
    "    for score in rf_scores:\n",
    "        rf_row += f\" {score:.2f} |\"\n",
    "    rf_row += f\" **{avg_rf:.2f}** |\"\n",
    "    print(rf_row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_experiment_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
