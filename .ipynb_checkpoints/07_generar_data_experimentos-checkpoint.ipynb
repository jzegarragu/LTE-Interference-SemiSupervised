{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c863149-8a18-4f29-95bc-6c5b7bfb41fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GENERANDO DATASET AISLADOS PARA AUDITORÍA ---\n",
      "Carrier: Carrier_C4_9435\n",
      "Teacher Base: resnet50\n",
      "Experimentos a generar: ['PSEUDO_EXP_3.3_Umb70', 'PSEUDO_EXP_3.3_Umb90', 'PSEUDO_EXP_3.4_Auto80', 'PSEUDO_EXP_3.2_FixMatch95']\n",
      "Cargando Pesos Teacher: best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_20956\\3359714434.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Carpeta creada: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\EXPERIMENTOS_ABLACION\\PSEUDO_EXP_3.3_Umb70\n",
      " > Carpeta creada: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\EXPERIMENTOS_ABLACION\\PSEUDO_EXP_3.3_Umb90\n",
      " > Carpeta creada: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\EXPERIMENTOS_ABLACION\\PSEUDO_EXP_3.4_Auto80\n",
      " > Carpeta creada: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\EXPERIMENTOS_ABLACION\\PSEUDO_EXP_3.2_FixMatch95\n",
      "\n",
      "Procesando 4285 imágenes sin etiquetar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distribuyendo Data: 100%|██████████████████████████████████████████████████████████| 4285/4285 [01:02<00:00, 68.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESUMEN DE GENERACIÓN (AUDITORÍA) ---\n",
      "[PSEUDO_EXP_3.3_Umb70] (Umbral >=0.7): 3713 imágenes generadas.\n",
      "[PSEUDO_EXP_3.3_Umb90] (Umbral >=0.9): 3081 imágenes generadas.\n",
      "[PSEUDO_EXP_3.4_Auto80] (Umbral >=0.8): 3442 imágenes generadas.\n",
      "[PSEUDO_EXP_3.2_FixMatch95] (Umbral >=0.95): 2725 imágenes generadas.\n",
      "\n",
      "✅ Datos listos en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\EXPERIMENTOS_ABLACION\n",
      "Tu carpeta 'PSEUDO' original NO ha sido tocada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 07_generar_data_experimentos.ipynb\n",
    "# ==============================================================================\n",
    "import torch\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import models\n",
    "import utils\n",
    "import config\n",
    "\n",
    "# --- CONFIGURACIÓN ESPECÍFICA ---\n",
    "CARRIER_TARGET = \"Carrier_C4_9435\"\n",
    "TEACHER_ARCH = \"resnet50\" # El Teacher ganador del C4\n",
    "DEVICE = torch.device(config.DEVICE)\n",
    "\n",
    "# Rutas Base\n",
    "base_results = config.RESULTS_DIR # .../Carrier_C4_9435\n",
    "unlabeled_dir = config.UNLABELED_DIR\n",
    "class_names = sorted([p.name for p in config.TRAIN_VAL_DIR.iterdir() if p.is_dir()])\n",
    "\n",
    "# --- DEFINICIÓN DE EXPERIMENTOS Y UMBRALES ---\n",
    "# Cada entrada creará una carpeta INDEPENDIENTE con sus propias copias de imágenes.\n",
    "EXPERIMENTS_DICT = {\n",
    "    # Exp 3.3: Ablación de Umbral (Validar por qué elegiste 80%)\n",
    "    \"PSEUDO_EXP_3.3_Umb70\": 0.70,\n",
    "    \"PSEUDO_EXP_3.3_Umb90\": 0.90,\n",
    "    \n",
    "    # Exp 3.4: Ablación del Experto (Tu modelo pero SIN tu revisión manual)\n",
    "    \"PSEUDO_EXP_3.4_Auto80\": 0.80, \n",
    "\n",
    "    # Exp 3.2: Comparativa vs FixMatch (SOTA Automático)\n",
    "    \"PSEUDO_EXP_3.2_FixMatch95\": 0.95\n",
    "}\n",
    "\n",
    "print(f\"--- GENERANDO DATASET AISLADOS PARA AUDITORÍA ---\")\n",
    "print(f\"Carrier: {CARRIER_TARGET}\")\n",
    "print(f\"Teacher Base: {TEACHER_ARCH}\")\n",
    "print(f\"Experimentos a generar: {list(EXPERIMENTS_DICT.keys())}\")\n",
    "\n",
    "# 1. CARGAR EL TEACHER (Solo lectura)\n",
    "def find_best_teacher_checkpoint(model_arch):\n",
    "    # Busca la carpeta del teacher_resnet50 existente en RESULTADOS\n",
    "    candidates = sorted([d for d in base_results.iterdir() if f\"teacher_{model_arch}\" in d.name])\n",
    "    if not candidates: raise FileNotFoundError(\"No se encontró carpeta del Teacher ResNet50\")\n",
    "    return candidates[-1] / \"best_model.pth\"\n",
    "\n",
    "ckpt_path = find_best_teacher_checkpoint(TEACHER_ARCH)\n",
    "print(f\"Cargando Pesos Teacher: {ckpt_path.name}\")\n",
    "\n",
    "model = models.make_model(TEACHER_ARCH, len(class_names), resnet_use_pretrain=False)\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 2. CREAR ESTRUCTURA DE CARPETAS AISLADAS\n",
    "# Creamos una carpeta raiz separada para no mezclar con la oficial\n",
    "root_exp_dir = base_results / \"EXPERIMENTOS_ABLACION\"\n",
    "if root_exp_dir.exists():\n",
    "    print(\"Limpiando carpeta de experimentos previa...\")\n",
    "    shutil.rmtree(root_exp_dir)\n",
    "root_exp_dir.mkdir()\n",
    "\n",
    "# Crear subcarpetas para cada experimento y cada clase\n",
    "for exp_name in EXPERIMENTS_DICT.keys():\n",
    "    exp_path = root_exp_dir / exp_name\n",
    "    exp_path.mkdir()\n",
    "    for cname in class_names:\n",
    "        (exp_path / cname).mkdir()\n",
    "    print(f\" > Carpeta creada: {exp_path}\")\n",
    "\n",
    "# 3. INFERENCIA Y DISTRIBUCIÓN\n",
    "unlabeled_images = list(unlabeled_dir.glob(\"*.png\"))\n",
    "print(f\"\\nProcesando {len(unlabeled_images)} imágenes sin etiquetar...\")\n",
    "\n",
    "stats = {k: 0 for k in EXPERIMENTS_DICT.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_path in tqdm(unlabeled_images, desc=\"Distribuyendo Data\"):\n",
    "        try:\n",
    "            # Preprocesamiento\n",
    "            img_tensor = utils.load_png_gray(img_path)\n",
    "            # Resize obligatorio para ResNet\n",
    "            img_tensor = torch.nn.functional.interpolate(\n",
    "                img_tensor.unsqueeze(0), size=(224, 224), mode=\"bilinear\", align_corners=False\n",
    "            ).squeeze(0)\n",
    "            img_tensor = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "            # Predicción del Teacher\n",
    "            logits = model(img_tensor)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            max_prob, pred_idx = torch.max(probs, dim=1)\n",
    "            \n",
    "            confidence = max_prob.item()\n",
    "            pred_class = class_names[pred_idx.item()]\n",
    "\n",
    "            # LOGICA DE DISTRIBUCIÓN:\n",
    "            # Una imagen puede ir a múltiples experimentos si cumple sus umbrales individuales.\n",
    "            # Cada experimento es un universo aislado.\n",
    "            for exp_name, threshold in EXPERIMENTS_DICT.items():\n",
    "                if confidence >= threshold:\n",
    "                    # Copiamos la imagen a la carpeta específica de ESE experimento\n",
    "                    dest = root_exp_dir / exp_name / pred_class / img_path.name\n",
    "                    shutil.copy(str(img_path), str(dest))\n",
    "                    stats[exp_name] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en {img_path.name}: {e}\")\n",
    "\n",
    "print(\"\\n--- RESUMEN DE GENERACIÓN (AUDITORÍA) ---\")\n",
    "for exp_name, count in stats.items():\n",
    "    print(f\"[{exp_name}] (Umbral >={EXPERIMENTS_DICT[exp_name]}): {count} imágenes generadas.\")\n",
    "\n",
    "print(f\"\\n✅ Datos listos en: {root_exp_dir}\")\n",
    "print(\"Tu carpeta 'PSEUDO' original NO ha sido tocada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10f0b9-59ec-4be3-a362-b376619fba9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
