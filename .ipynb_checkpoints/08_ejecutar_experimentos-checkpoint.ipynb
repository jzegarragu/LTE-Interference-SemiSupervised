{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b348241e-6ce0-4be4-b300-bf7fd659555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 08_ejecutar_experimentos.ipynb\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "# CELDA 2: Importaciones\n",
    "# ==============================================================================\n",
    "# --- Importaciones Est√°ndar ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# --- Importar desde nuestros m√≥dulos locales ---\n",
    "import config\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b484d3-1323-4a2f-8dc9-078d3c31304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 2: Clase Asistente para Tesis (ThesisHelper) - CORREGIDA\n",
    "# ==============================================================================\n",
    "class ThesisHelper:\n",
    "    \"\"\"\n",
    "    Una clase para gestionar el logging, guardado de checkpoints y generaci√≥n\n",
    "    de artefactos para una tesis durante el entrenamiento de un modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, class_names, base_dir, run_type='teacher'):\n",
    "        self.params = params\n",
    "        self.class_names = class_names\n",
    "        \n",
    "        # --- CORRECCI√ìN AQU√ç ---\n",
    "        # Buscamos si existe un sufijo de experimento en los par√°metros\n",
    "        suffix = params.get('EXPERIMENT_SUFFIX', '') \n",
    "        \n",
    "        # El nombre ahora incluye el tipo de ejecuci√≥n y el sufijo si existe\n",
    "        if run_type == 'student':\n",
    "            # Ej: student_trained_with_win_teachersresnet50_EXP_3.2_FixMatch\n",
    "            self.run_name = f\"student_trained_with_win_teachers{params['MODEL_NAME']}{suffix}\"\n",
    "        else: \n",
    "            self.run_name = f\"{run_type}_{params['MODEL_NAME']}\"\n",
    "            \n",
    "        self.output_dir = Path(base_dir) / self.run_name\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.run_type = run_type \n",
    "        \n",
    "        self.history = []\n",
    "        self.best_f1_macro = -1.0\n",
    "        self.best_epoch_metrics = None\n",
    "        \n",
    "        print(f\"ThesisHelper inicializado para '{self.run_name}'. Artefactos se guardar√°n en: {self.output_dir}\")\n",
    "\n",
    "    def log_epoch(self, model, metrics):\n",
    "        \"\"\"Registra las m√©tricas de una √©poca y guarda el mejor checkpoint.\"\"\"\n",
    "        self.history.append(metrics)\n",
    "        current_f1_macro = metrics['f1m']\n",
    "        \n",
    "        if current_f1_macro > self.best_f1_macro:\n",
    "            self.best_f1_macro = current_f1_macro\n",
    "            self.best_epoch_metrics = metrics\n",
    "            print(f\"üöÄ Nuevo mejor F1-Macro: {self.best_f1_macro:.4f} en la √©poca {metrics['epoch']}. Guardando checkpoint...\")\n",
    "            self._save_checkpoint(model)\n",
    "\n",
    "    def _save_checkpoint(self, model):\n",
    "        \"\"\"Guarda el state_dict del modelo.\"\"\"\n",
    "        torch.save(model.state_dict(), self.output_dir / 'best_model.pth')\n",
    "\n",
    "    def finalize(self, total_duration_seconds):\n",
    "        \"\"\"Genera todos los artefactos finales despu√©s del entrenamiento.\"\"\"\n",
    "        if not self.history:\n",
    "            print(\"No hay historial para finalizar. Saltando la generaci√≥n de artefactos.\")\n",
    "            return\n",
    "\n",
    "        # 1. Guardar historial y resumen\n",
    "        history_df = pd.DataFrame(self.history)\n",
    "        history_df.to_csv(self.output_dir / 'training_history.csv', index=False)\n",
    "        \n",
    "        summary = self.best_epoch_metrics.copy()\n",
    "        summary['total_duration_min'] = total_duration_seconds / 60\n",
    "        cm = summary.pop('cm', None) \n",
    "        \n",
    "        with open(self.output_dir / 'summary.json', 'w') as f:\n",
    "            json.dump(summary, f, indent=4)\n",
    "            \n",
    "        print(f\"üìÑ Historial y resumen guardados.\")\n",
    "\n",
    "        # 2. Generar y guardar gr√°ficas\n",
    "        self._plot_curves(history_df)\n",
    "        print(f\"üìä Gr√°ficas de entrenamiento guardadas.\")\n",
    "        \n",
    "        # 3. Generar y guardar tabla LaTeX\n",
    "        self._generate_latex_table(summary, cm)\n",
    "        print(f\"üìã Tabla LaTeX generada.\")\n",
    "        \n",
    "        # 4. Registrar en el Excel principal\n",
    "        self._log_to_excel(summary, cm)\n",
    "        print(f\"‚úÖ M√©tricas finales registradas en Excel.\")\n",
    "\n",
    "    def _plot_curves(self, df):\n",
    "        \"\"\"Genera y guarda las curvas de entrenamiento y validaci√≥n.\"\"\"\n",
    "        best_epoch = self.best_epoch_metrics['epoch']\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "        fig.suptitle(f'Curvas de Entrenamiento para {self.run_name}', fontsize=16)\n",
    "\n",
    "        ax1.plot(df['epoch'], df['tr_loss'], 'o-', label='Training Loss')\n",
    "        ax1.plot(df['epoch'], df['loss'], 'o-', label='Validation Loss')\n",
    "        ax1.axvline(x=best_epoch, color='r', linestyle='--', label=f'Mejor √âpoca ({best_epoch})')\n",
    "        ax1.set_ylabel('P√©rdida (Loss)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "        \n",
    "        best_loss = self.best_epoch_metrics['loss']\n",
    "        ax1.annotate(f'Mejor F1-Macro\\nVal Loss: {best_loss:.4f}',\n",
    "                     xy=(best_epoch, best_loss),\n",
    "                     xytext=(best_epoch + 3, best_loss + 0.1*df['loss'].max()),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", ec=\"black\", lw=1, alpha=0.7))\n",
    "\n",
    "        ax2.plot(df['epoch'], df['tr_acc'], 'o-', label='Training Accuracy')\n",
    "        ax2.plot(df['epoch'], df['acc'], 'o-', label='Validation Accuracy')\n",
    "        ax2.plot(df['epoch'], df['f1m'], 'o-', label='Validation F1-Macro', linewidth=2, markersize=8)\n",
    "        ax2.axvline(x=best_epoch, color='r', linestyle='--')\n",
    "        ax2.set_xlabel('√âpoca')\n",
    "        ax2.set_ylabel('M√©trica')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax2.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1.0))\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(self.output_dir / 'training_curves.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def _generate_latex_table(self, summary, cm):\n",
    "        latex_str = f\"\"\"\n",
    "\\\\begin{{table}}[h!]\n",
    "\\\\centering\n",
    "\\\\caption{{Resumen del entrenamiento del modelo {self.run_name.replace('_', ' ')} y m√©tricas finales en la mejor √©poca.}}\n",
    "\\\\label{{tab:training_summary_{self.run_name}}}\n",
    "\\\\begin{{tabular}}{{ll}}\n",
    "\\\\hline\n",
    "\\\\textbf{{Par√°metro}} & \\\\textbf{{Valor}} \\\\\\\\\n",
    "\\\\hline\n",
    "Modelo Base & {self.params['MODEL_NAME']} \\\\\\\\\n",
    "Mejor √âpoca & {summary['epoch']} \\\\\\\\\n",
    "Duraci√≥n Total (min) & {summary['total_duration_min']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{M√©trica de Validaci√≥n}} & \\\\textbf{{Valor}} \\\\\\\\\n",
    "\\\\hline\n",
    "F1-Macro (Mejor) & {summary['f1m']:.4f} \\\\\\\\\n",
    "Exactitud (Accuracy) & {summary['acc']:.4f} \\\\\\\\\n",
    "P√©rdida (Loss) & {summary['loss']:.4f} \\\\\\\\\n",
    "Recall (Macro) & {summary['recm']:.4f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\end{{table}}\n",
    "        \"\"\"\n",
    "        with open(self.output_dir / 'summary_table.tex', 'w') as f:\n",
    "            f.write(latex_str)\n",
    "\n",
    "    def _log_to_excel(self, summary, cm):\n",
    "        metrics_to_log = {\n",
    "            'carrier': config.CARRIER,\n",
    "            'model_name': self.params['MODEL_NAME'],\n",
    "            'run_tag': self.run_name, # Esto capturar√° el nombre completo con el sufijo\n",
    "            'num_classes': len(self.class_names),\n",
    "            'acc': summary['acc'],\n",
    "            'loss': summary['loss'],\n",
    "            'f1m': summary['f1m'],\n",
    "            'f1w': summary['f1w'],\n",
    "            'recm': summary['recm'],\n",
    "            'cm': cm,\n",
    "            'epochs': self.params['EPOCHS'],\n",
    "            'batch_size': self.params['BATCH_SIZE'],\n",
    "            'lr': self.params['LR'],\n",
    "            'weight_decay': self.params['WEIGHT_DECAY'],\n",
    "            'notes': f\"Student Exp: {self.run_name}\"\n",
    "        }\n",
    "        utils.log_metrics_excel(config.EXCEL_PATH, config.RESULTS_DIR, self.class_names, metrics_to_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a064a2-c57b-4421-afb1-d8dbb69ab11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 3: Clases de Dataset, Transformaciones y Bucle de Entrenamiento\n",
    "# ==============================================================================\n",
    "\n",
    "class RandomTimeShift(torch.nn.Module):\n",
    "    def __init__(self, max_frac=0.1):\n",
    "        super().__init__()\n",
    "        self.max_frac = max_frac\n",
    "    def forward(self, x):\n",
    "        _, H, W = x.shape\n",
    "        s = int(random.uniform(-self.max_frac, self.max_frac) * W)\n",
    "        return torch.roll(x, shifts=s, dims=-1)\n",
    "\n",
    "class RandomGain(torch.nn.Module):\n",
    "    def __init__(self, a=0.95, b=1.05):\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "    def forward(self, x):\n",
    "        g = random.uniform(self.a, self.b)\n",
    "        return (x * g).clamp(0, 1)\n",
    "\n",
    "weak_aug = T.Compose([\n",
    "    RandomTimeShift(0.08),\n",
    "    RandomGain(0.95, 1.05),\n",
    "])\n",
    "\n",
    "class LabeledSpectro(Dataset):\n",
    "    def __init__(self, files, labels, transform=None):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self, i):\n",
    "        path = self.files[i]\n",
    "        try:\n",
    "            x = utils.load_png_gray(path)\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "            y = self.labels[i]\n",
    "            return x, y\n",
    "        except Exception as e:\n",
    "            print(f\"[dataset_warning] Saltando archivo por error: {e}\")\n",
    "            return torch.zeros(1, config.IMG_H, config.IMG_W, dtype=torch.float32), self.labels[i]\n",
    "\n",
    "def maybe_resize_for_resnet(x, should_resize):\n",
    "    if should_resize:\n",
    "        return torch.nn.functional.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "    return x\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience, min_delta, mode='max', restore_best=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.restore_best = restore_best\n",
    "        self.best = -float('inf') if mode == 'max' else float('inf')\n",
    "        self.wait = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, metric, model):\n",
    "        is_better = (metric > self.best + self.min_delta) if self.mode == 'max' else (metric < self.best - self.min_delta)\n",
    "        if is_better:\n",
    "            self.best = metric\n",
    "            self.wait = 0\n",
    "            if self.restore_best:\n",
    "                self.best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            return False\n",
    "        self.wait += 1\n",
    "        return self.wait >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        if self.restore_best and self.best_state is not None:\n",
    "            model.load_state_dict(self.best_state)\n",
    "\n",
    "def evaluate(model, loader, criterion, params):\n",
    "    device = torch.device(config.DEVICE)\n",
    "    model.eval()\n",
    "    va_loss, preds, gts = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = maybe_resize_for_resnet(xb, params.get('RESNET_RESIZE_TO_224', False))\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            va_loss += loss.item() * xb.size(0)\n",
    "            preds.append(logits.softmax(1).argmax(1).cpu())\n",
    "            gts.append(yb.cpu())\n",
    "    va_loss /= len(loader.dataset)\n",
    "    y_pred = torch.cat(preds).numpy()\n",
    "    y_true = torch.cat(gts).numpy()\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': va_loss,\n",
    "        'acc': accuracy_score(y_true, y_pred),\n",
    "        'f1m': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1w': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'recm': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'cm': confusion_matrix(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_student(params, train_loader, val_loader, num_classes, class_names):\n",
    "    device = torch.device(config.DEVICE)\n",
    "    torch.manual_seed(config.SEED)\n",
    "    np.random.seed(config.SEED)\n",
    "\n",
    "    # Inicializar el Asistente de Tesis\n",
    "    helper = ThesisHelper(params, class_names, base_dir=config.RESULTS_DIR, run_type='student')\n",
    "\n",
    "    model = models.make_model(\n",
    "        params['MODEL_NAME'], \n",
    "        num_classes, \n",
    "        params.get('RESNET_USE_PRETRAIN', True)\n",
    "    ).to(device)\n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), lr=params['LR'], momentum=params['MOMENTUM'], weight_decay=params['WEIGHT_DECAY'])\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=params['EPOCHS'], eta_min=params['LR'] * config.ETA_MIN_FACTOR)\n",
    "    \n",
    "    es = EarlyStopping(patience=params['PATIENCE'], min_delta=config.MIN_DELTA, restore_best=False) # restore_best=False, ThesisHelper se encarga\n",
    "    t0 = time.time()\n",
    "\n",
    "    for ep in range(1, params['EPOCHS'] + 1):\n",
    "        model.train()\n",
    "        tr_loss, n = 0.0, 0\n",
    "        tr_preds, tr_gts = [], [] # Para calcular tr_acc\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = maybe_resize_for_resnet(xb, params.get('RESNET_RESIZE_TO_224', False))\n",
    "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "            \n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.CLIP_MAX_NORM)\n",
    "            opt.step()\n",
    "            \n",
    "            tr_loss += loss.item() * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "            \n",
    "            # Guardar predicciones y etiquetas para tr_acc\n",
    "            tr_preds.append(logits.softmax(1).argmax(1).cpu())\n",
    "            tr_gts.append(yb.cpu())\n",
    "        \n",
    "        tr_loss /= n\n",
    "        sched.step()\n",
    "\n",
    "        # Calcular tr_acc\n",
    "        y_pred_tr = torch.cat(tr_preds).numpy()\n",
    "        y_true_tr = torch.cat(tr_gts).numpy()\n",
    "        tr_acc = accuracy_score(y_true_tr, y_pred_tr)\n",
    "\n",
    "        # Evaluar en validaci√≥n\n",
    "        val_metrics = evaluate(model, val_loader, crit, params)\n",
    "        monitor_metric_key = config.MONITOR.replace('_macro', 'm').replace('_weighted', 'w')\n",
    "        monitor_metric_val = val_metrics[monitor_metric_key]\n",
    "        \n",
    "        # Consolidar todas las m√©tricas de la √©poca\n",
    "        log_entry = {\n",
    "            'epoch': ep, 'tr_loss': tr_loss, 'tr_acc': tr_acc, \n",
    "            **val_metrics, 'lr': sched.get_last_lr()[0]\n",
    "        }\n",
    "        \n",
    "        # Usar ThesisHelper para registrar y guardar el mejor modelo\n",
    "        helper.log_epoch(model, log_entry)\n",
    "        \n",
    "        print(f\"[{params['MODEL_NAME']}] e{ep:03d}/{params['EPOCHS']} | tr_loss={tr_loss:.4f} | va_loss={val_metrics['loss']:.4f} | tr_acc={tr_acc:.4f} | va_acc={val_metrics['acc']:.4f} | {config.MONITOR}={monitor_metric_val:.4f}\")\n",
    "\n",
    "        # Comprobar Early Stopping\n",
    "        stop = es.step(monitor_metric_val, model)\n",
    "        if stop:\n",
    "            print(f\"Early stopping en epoch {ep} (mejor {config.MONITOR}={es.best:.4f}).\")\n",
    "            break\n",
    "\n",
    "    dur = time.time() - t0\n",
    "    \n",
    "    # Finalizar el proceso: guardar res√∫menes, gr√°ficas, etc.\n",
    "    helper.finalize(dur)\n",
    "    \n",
    "    # Cargar el mejor modelo guardado por el helper para devolverlo\n",
    "    best_model_path = helper.output_dir / 'best_model.pth'\n",
    "    if best_model_path.exists():\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        print(f\"Modelo final cargado desde el mejor checkpoint (F1-Macro: {helper.best_f1_macro:.4f}).\")\n",
    "\n",
    "    print(f\"[DONE] {params['MODEL_NAME']} | dur={dur/60:.1f} min | best_{config.MONITOR}={helper.best_f1_macro:.4f}\")\n",
    "    \n",
    "    return {'model': model, 'helper': helper}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3bcf0b-6a9a-45f5-a72e-3b43c7cb7735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set (Fijo): 51 muestras\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 05_ejecutar_experimentos.ipynb\n",
    "# ==============================================================================\n",
    "# [AQUI PEGA TUS IMPORTACIONES Y CLASES DE SIEMPRE: ThesisHelper, LabeledSpectro, etc.]\n",
    "# Aseg√∫rate de copiar la celda de importaciones y clases utilitarias del notebook 03.\n",
    "# ...\n",
    "\n",
    "import config\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- CONFIGURACI√ìN DE LA EJECUCI√ìN ---\n",
    "# Mapeamos la carpeta de origen (creada en el paso anterior) con el nombre del modelo de salida\n",
    "RUN_CONFIG = [\n",
    "    {\n",
    "        \"source_folder\": \"PSEUDO_EXP_3.2_FixMatch95\",\n",
    "        \"run_name\": \"EXP_3.2_FixMatch\",\n",
    "        \"desc\": \"Baseline SOTA Automatico (0.95)\"\n",
    "    },\n",
    "    {\n",
    "        \"source_folder\": \"PSEUDO_EXP_3.4_Auto80\",\n",
    "        \"run_name\": \"EXP_3.4_SinExperto\",\n",
    "        \"desc\": \"Ablacion Humana (Auto 0.80)\"\n",
    "    },\n",
    "    {\n",
    "        \"source_folder\": \"PSEUDO_EXP_3.3_Umb70\",\n",
    "        \"run_name\": \"EXP_3.3_Umb70\",\n",
    "        \"desc\": \"Sensibilidad Umbral 0.70\"\n",
    "    },\n",
    "    {\n",
    "        \"source_folder\": \"PSEUDO_EXP_3.3_Umb90\",\n",
    "        \"run_name\": \"EXP_3.3_Umb90\",\n",
    "        \"desc\": \"Sensibilidad Umbral 0.90\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configuraci√≥n Base (C4 + ResNet50)\n",
    "base_exp_dir = config.RESULTS_DIR / \"EXPERIMENTOS_ABLACION\"\n",
    "class_names = sorted([p.name for p in config.TRAIN_VAL_DIR.iterdir() if p.is_dir()])\n",
    "cls2idx = {name: i for i, name in enumerate(class_names)}\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# 1. CARGAR DATASET ORIGINAL (Train/Val Split Fijo)\n",
    "# Usamos seed 42 para garantizar que el set de validaci√≥n sea ID√âNTICO al de tu tesis\n",
    "all_original_files, all_original_labels = [], []\n",
    "for class_name in class_names:\n",
    "    class_path = config.TRAIN_VAL_DIR / class_name\n",
    "    files = list(class_path.glob(\"*.png\"))\n",
    "    all_original_files.extend(files)\n",
    "    all_original_labels.extend([cls2idx[class_name]] * len(files))\n",
    "\n",
    "original_train_files, val_files, original_train_labels, val_labels = train_test_split(\n",
    "    all_original_files, all_original_labels, test_size=0.2, random_state=config.SEED, stratify=all_original_labels\n",
    ")\n",
    "# Dataset Validaci√≥n (El juez imparcial)\n",
    "val_ds = LabeledSpectro(val_files, val_labels, transform=None) \n",
    "print(f\"Validation Set (Fijo): {len(val_ds)} muestras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaef24fa-ab8c-4105-8864-cb3a26a32164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üß™ INICIANDO: EXP_3.2_FixMatch\n",
      "   Fuente: PSEUDO_EXP_3.2_FixMatch95\n",
      "   Objetivo: Baseline SOTA Automatico (0.95)\n",
      "============================================================\n",
      "   > Pseudo-etiquetas cargadas: 2725\n",
      "   > Entrenando ResNet50 Student...\n",
      "ThesisHelper inicializado para 'student_trained_with_win_teachersresnet50_EXP_3.2_FixMatch'. Artefactos se guardar√°n en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\student_trained_with_win_teachersresnet50_EXP_3.2_FixMatch\n",
      "üöÄ Nuevo mejor F1-Macro: 0.6331 en la √©poca 1. Guardando checkpoint...\n",
      "[resnet50] e001/300 | tr_loss=0.6242 | va_loss=0.9947 | tr_acc=0.8040 | va_acc=0.6863 | f1_macro=0.6331\n",
      "üöÄ Nuevo mejor F1-Macro: 0.7917 en la √©poca 2. Guardando checkpoint...\n",
      "[resnet50] e002/300 | tr_loss=0.1204 | va_loss=0.5625 | tr_acc=0.9659 | va_acc=0.8039 | f1_macro=0.7917\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8476 en la √©poca 3. Guardando checkpoint...\n",
      "[resnet50] e003/300 | tr_loss=0.0736 | va_loss=0.5261 | tr_acc=0.9792 | va_acc=0.8431 | f1_macro=0.8476\n",
      "[resnet50] e004/300 | tr_loss=0.0460 | va_loss=0.5023 | tr_acc=0.9894 | va_acc=0.8235 | f1_macro=0.8188\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8812 en la √©poca 5. Guardando checkpoint...\n",
      "[resnet50] e005/300 | tr_loss=0.0363 | va_loss=0.3515 | tr_acc=0.9901 | va_acc=0.8824 | f1_macro=0.8812\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8838 en la √©poca 6. Guardando checkpoint...\n",
      "[resnet50] e006/300 | tr_loss=0.0274 | va_loss=0.3719 | tr_acc=0.9945 | va_acc=0.8824 | f1_macro=0.8838\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9225 en la √©poca 7. Guardando checkpoint...\n",
      "[resnet50] e007/300 | tr_loss=0.0183 | va_loss=0.2917 | tr_acc=0.9962 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e008/300 | tr_loss=0.0149 | va_loss=0.2775 | tr_acc=0.9973 | va_acc=0.9020 | f1_macro=0.9016\n",
      "[resnet50] e009/300 | tr_loss=0.0162 | va_loss=0.3070 | tr_acc=0.9956 | va_acc=0.9020 | f1_macro=0.9013\n",
      "[resnet50] e010/300 | tr_loss=0.0138 | va_loss=0.2465 | tr_acc=0.9969 | va_acc=0.9020 | f1_macro=0.9029\n",
      "[resnet50] e011/300 | tr_loss=0.0110 | va_loss=0.3327 | tr_acc=0.9966 | va_acc=0.8824 | f1_macro=0.8890\n",
      "[resnet50] e012/300 | tr_loss=0.0135 | va_loss=0.2749 | tr_acc=0.9959 | va_acc=0.8627 | f1_macro=0.8612\n",
      "[resnet50] e013/300 | tr_loss=0.0109 | va_loss=0.2318 | tr_acc=0.9980 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e014/300 | tr_loss=0.0104 | va_loss=0.3341 | tr_acc=0.9980 | va_acc=0.8824 | f1_macro=0.8841\n",
      "[resnet50] e015/300 | tr_loss=0.0076 | va_loss=0.2434 | tr_acc=0.9986 | va_acc=0.8824 | f1_macro=0.8825\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9235 en la √©poca 16. Guardando checkpoint...\n",
      "[resnet50] e016/300 | tr_loss=0.0110 | va_loss=0.2005 | tr_acc=0.9966 | va_acc=0.9216 | f1_macro=0.9235\n",
      "[resnet50] e017/300 | tr_loss=0.0053 | va_loss=0.1610 | tr_acc=0.9993 | va_acc=0.9216 | f1_macro=0.9198\n",
      "[resnet50] e018/300 | tr_loss=0.0052 | va_loss=0.2280 | tr_acc=0.9980 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e019/300 | tr_loss=0.0044 | va_loss=0.2635 | tr_acc=0.9997 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e020/300 | tr_loss=0.0036 | va_loss=0.1739 | tr_acc=1.0000 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e021/300 | tr_loss=0.0034 | va_loss=0.2333 | tr_acc=0.9997 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e022/300 | tr_loss=0.0026 | va_loss=0.2379 | tr_acc=0.9993 | va_acc=0.9216 | f1_macro=0.9225\n",
      "Early stopping en epoch 22 (mejor f1_macro=0.9225).\n",
      "üìÑ Historial y resumen guardados.\n",
      "üìä Gr√°ficas de entrenamiento guardadas.\n",
      "üìã Tabla LaTeX generada.\n",
      "‚úÖ M√©tricas guardadas en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\metrics_por_carrier.xlsx\n",
      "‚úÖ M√©tricas finales registradas en Excel.\n",
      "Modelo final cargado desde el mejor checkpoint (F1-Macro: 0.9235).\n",
      "[DONE] resnet50 | dur=7.5 min | best_f1_macro=0.9235\n",
      "‚úÖ EXP_3.2_FixMatch Completado.\n",
      "\n",
      "============================================================\n",
      "üß™ INICIANDO: EXP_3.4_SinExperto\n",
      "   Fuente: PSEUDO_EXP_3.4_Auto80\n",
      "   Objetivo: Ablacion Humana (Auto 0.80)\n",
      "============================================================\n",
      "   > Pseudo-etiquetas cargadas: 3442\n",
      "   > Entrenando ResNet50 Student...\n",
      "ThesisHelper inicializado para 'student_trained_with_win_teachersresnet50_EXP_3.4_SinExperto'. Artefactos se guardar√°n en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\student_trained_with_win_teachersresnet50_EXP_3.4_SinExperto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3864660564.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Nuevo mejor F1-Macro: 0.1652 en la √©poca 1. Guardando checkpoint...\n",
      "[resnet50] e001/300 | tr_loss=0.6115 | va_loss=1.7489 | tr_acc=0.7984 | va_acc=0.2353 | f1_macro=0.1652\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8238 en la √©poca 2. Guardando checkpoint...\n",
      "[resnet50] e002/300 | tr_loss=0.1554 | va_loss=0.5259 | tr_acc=0.9567 | va_acc=0.8235 | f1_macro=0.8238\n",
      "[resnet50] e003/300 | tr_loss=0.0839 | va_loss=0.4327 | tr_acc=0.9759 | va_acc=0.8235 | f1_macro=0.8227\n",
      "[resnet50] e004/300 | tr_loss=0.0642 | va_loss=0.4087 | tr_acc=0.9792 | va_acc=0.8235 | f1_macro=0.8197\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9013 en la √©poca 5. Guardando checkpoint...\n",
      "[resnet50] e005/300 | tr_loss=0.0467 | va_loss=0.3230 | tr_acc=0.9868 | va_acc=0.9020 | f1_macro=0.9013\n",
      "[resnet50] e006/300 | tr_loss=0.0493 | va_loss=0.4157 | tr_acc=0.9835 | va_acc=0.8431 | f1_macro=0.8399\n",
      "[resnet50] e007/300 | tr_loss=0.0414 | va_loss=0.3726 | tr_acc=0.9863 | va_acc=0.8824 | f1_macro=0.8862\n",
      "[resnet50] e008/300 | tr_loss=0.0341 | va_loss=0.1971 | tr_acc=0.9918 | va_acc=0.8627 | f1_macro=0.8624\n",
      "[resnet50] e009/300 | tr_loss=0.0340 | va_loss=0.3793 | tr_acc=0.9888 | va_acc=0.8824 | f1_macro=0.8822\n",
      "[resnet50] e010/300 | tr_loss=0.0237 | va_loss=0.5164 | tr_acc=0.9937 | va_acc=0.8627 | f1_macro=0.8613\n",
      "[resnet50] e011/300 | tr_loss=0.0159 | va_loss=0.5234 | tr_acc=0.9967 | va_acc=0.8627 | f1_macro=0.8635\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9024 en la √©poca 12. Guardando checkpoint...\n",
      "[resnet50] e012/300 | tr_loss=0.0155 | va_loss=0.3200 | tr_acc=0.9953 | va_acc=0.9020 | f1_macro=0.9024\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9225 en la √©poca 13. Guardando checkpoint...\n",
      "[resnet50] e013/300 | tr_loss=0.0195 | va_loss=0.2450 | tr_acc=0.9945 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e014/300 | tr_loss=0.0124 | va_loss=0.3412 | tr_acc=0.9967 | va_acc=0.9020 | f1_macro=0.9037\n",
      "[resnet50] e015/300 | tr_loss=0.0106 | va_loss=0.2392 | tr_acc=0.9978 | va_acc=0.8824 | f1_macro=0.8827\n",
      "[resnet50] e016/300 | tr_loss=0.0103 | va_loss=0.2100 | tr_acc=0.9986 | va_acc=0.9216 | f1_macro=0.9221\n",
      "[resnet50] e017/300 | tr_loss=0.0138 | va_loss=0.3617 | tr_acc=0.9967 | va_acc=0.8824 | f1_macro=0.8816\n",
      "[resnet50] e018/300 | tr_loss=0.0088 | va_loss=0.3663 | tr_acc=0.9981 | va_acc=0.8627 | f1_macro=0.8646\n",
      "[resnet50] e019/300 | tr_loss=0.0086 | va_loss=0.2361 | tr_acc=0.9975 | va_acc=0.8824 | f1_macro=0.8812\n",
      "[resnet50] e020/300 | tr_loss=0.0068 | va_loss=0.2393 | tr_acc=0.9975 | va_acc=0.9216 | f1_macro=0.9214\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9420 en la √©poca 21. Guardando checkpoint...\n",
      "[resnet50] e021/300 | tr_loss=0.0055 | va_loss=0.2449 | tr_acc=0.9992 | va_acc=0.9412 | f1_macro=0.9420\n",
      "[resnet50] e022/300 | tr_loss=0.0057 | va_loss=0.5192 | tr_acc=0.9989 | va_acc=0.8431 | f1_macro=0.8385\n",
      "[resnet50] e023/300 | tr_loss=0.0063 | va_loss=0.3111 | tr_acc=0.9984 | va_acc=0.8824 | f1_macro=0.8842\n",
      "[resnet50] e024/300 | tr_loss=0.0046 | va_loss=0.4286 | tr_acc=0.9989 | va_acc=0.8627 | f1_macro=0.8536\n",
      "[resnet50] e025/300 | tr_loss=0.0046 | va_loss=0.4579 | tr_acc=0.9989 | va_acc=0.8824 | f1_macro=0.8796\n",
      "[resnet50] e026/300 | tr_loss=0.0036 | va_loss=0.5509 | tr_acc=0.9997 | va_acc=0.8824 | f1_macro=0.8816\n",
      "[resnet50] e027/300 | tr_loss=0.0031 | va_loss=0.4395 | tr_acc=0.9997 | va_acc=0.9020 | f1_macro=0.9024\n",
      "[resnet50] e028/300 | tr_loss=0.0036 | va_loss=0.4984 | tr_acc=0.9995 | va_acc=0.8431 | f1_macro=0.8368\n",
      "[resnet50] e029/300 | tr_loss=0.0016 | va_loss=0.4490 | tr_acc=1.0000 | va_acc=0.8627 | f1_macro=0.8619\n",
      "[resnet50] e030/300 | tr_loss=0.0022 | va_loss=0.4610 | tr_acc=1.0000 | va_acc=0.8824 | f1_macro=0.8816\n",
      "[resnet50] e031/300 | tr_loss=0.0043 | va_loss=0.5416 | tr_acc=0.9989 | va_acc=0.8627 | f1_macro=0.8598\n",
      "[resnet50] e032/300 | tr_loss=0.0035 | va_loss=0.5273 | tr_acc=0.9989 | va_acc=0.8431 | f1_macro=0.8368\n",
      "[resnet50] e033/300 | tr_loss=0.0053 | va_loss=0.7887 | tr_acc=0.9984 | va_acc=0.8431 | f1_macro=0.8385\n",
      "[resnet50] e034/300 | tr_loss=0.0043 | va_loss=0.3594 | tr_acc=0.9997 | va_acc=0.8627 | f1_macro=0.8646\n",
      "[resnet50] e035/300 | tr_loss=0.0070 | va_loss=0.4196 | tr_acc=0.9975 | va_acc=0.8627 | f1_macro=0.8593\n",
      "[resnet50] e036/300 | tr_loss=0.0023 | va_loss=0.4028 | tr_acc=1.0000 | va_acc=0.9020 | f1_macro=0.9049\n",
      "Early stopping en epoch 36 (mejor f1_macro=0.9420).\n",
      "üìÑ Historial y resumen guardados.\n",
      "üìä Gr√°ficas de entrenamiento guardadas.\n",
      "üìã Tabla LaTeX generada.\n",
      "‚úÖ M√©tricas guardadas en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\metrics_por_carrier.xlsx\n",
      "‚úÖ M√©tricas finales registradas en Excel.\n",
      "Modelo final cargado desde el mejor checkpoint (F1-Macro: 0.9420).\n",
      "[DONE] resnet50 | dur=15.5 min | best_f1_macro=0.9420\n",
      "‚úÖ EXP_3.4_SinExperto Completado.\n",
      "\n",
      "============================================================\n",
      "üß™ INICIANDO: EXP_3.3_Umb70\n",
      "   Fuente: PSEUDO_EXP_3.3_Umb70\n",
      "   Objetivo: Sensibilidad Umbral 0.70\n",
      "============================================================\n",
      "   > Pseudo-etiquetas cargadas: 3713\n",
      "   > Entrenando ResNet50 Student...\n",
      "ThesisHelper inicializado para 'student_trained_with_win_teachersresnet50_EXP_3.3_Umb70'. Artefactos se guardar√°n en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\student_trained_with_win_teachersresnet50_EXP_3.3_Umb70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3864660564.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Nuevo mejor F1-Macro: 0.7416 en la √©poca 1. Guardando checkpoint...\n",
      "[resnet50] e001/300 | tr_loss=0.6326 | va_loss=0.7774 | tr_acc=0.7838 | va_acc=0.7451 | f1_macro=0.7416\n",
      "[resnet50] e002/300 | tr_loss=0.1751 | va_loss=1.6449 | tr_acc=0.9461 | va_acc=0.4510 | f1_macro=0.3029\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8571 en la √©poca 3. Guardando checkpoint...\n",
      "[resnet50] e003/300 | tr_loss=0.1206 | va_loss=0.2944 | tr_acc=0.9612 | va_acc=0.8627 | f1_macro=0.8571\n",
      "[resnet50] e004/300 | tr_loss=0.0931 | va_loss=0.4669 | tr_acc=0.9714 | va_acc=0.8039 | f1_macro=0.7827\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9208 en la √©poca 5. Guardando checkpoint...\n",
      "[resnet50] e005/300 | tr_loss=0.0738 | va_loss=0.1939 | tr_acc=0.9755 | va_acc=0.9216 | f1_macro=0.9208\n",
      "[resnet50] e006/300 | tr_loss=0.0638 | va_loss=0.2827 | tr_acc=0.9786 | va_acc=0.9020 | f1_macro=0.9013\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9244 en la √©poca 7. Guardando checkpoint...\n",
      "[resnet50] e007/300 | tr_loss=0.0522 | va_loss=0.3142 | tr_acc=0.9839 | va_acc=0.9216 | f1_macro=0.9244\n",
      "[resnet50] e008/300 | tr_loss=0.0455 | va_loss=0.4993 | tr_acc=0.9854 | va_acc=0.8431 | f1_macro=0.8400\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9420 en la √©poca 9. Guardando checkpoint...\n",
      "[resnet50] e009/300 | tr_loss=0.0364 | va_loss=0.1430 | tr_acc=0.9883 | va_acc=0.9412 | f1_macro=0.9420\n",
      "[resnet50] e010/300 | tr_loss=0.0330 | va_loss=0.2059 | tr_acc=0.9913 | va_acc=0.9216 | f1_macro=0.9201\n",
      "[resnet50] e011/300 | tr_loss=0.0265 | va_loss=0.3225 | tr_acc=0.9929 | va_acc=0.9020 | f1_macro=0.9026\n",
      "[resnet50] e012/300 | tr_loss=0.0257 | va_loss=0.2879 | tr_acc=0.9926 | va_acc=0.9216 | f1_macro=0.9231\n",
      "[resnet50] e013/300 | tr_loss=0.0152 | va_loss=0.2713 | tr_acc=0.9949 | va_acc=0.9020 | f1_macro=0.9022\n",
      "[resnet50] e014/300 | tr_loss=0.0129 | va_loss=0.2660 | tr_acc=0.9959 | va_acc=0.9412 | f1_macro=0.9420\n",
      "[resnet50] e015/300 | tr_loss=0.0136 | va_loss=0.4180 | tr_acc=0.9964 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e016/300 | tr_loss=0.0141 | va_loss=0.2189 | tr_acc=0.9964 | va_acc=0.9020 | f1_macro=0.9071\n",
      "[resnet50] e017/300 | tr_loss=0.0071 | va_loss=0.2132 | tr_acc=0.9987 | va_acc=0.9412 | f1_macro=0.9420\n",
      "[resnet50] e018/300 | tr_loss=0.0117 | va_loss=0.2827 | tr_acc=0.9959 | va_acc=0.9412 | f1_macro=0.9420\n",
      "[resnet50] e019/300 | tr_loss=0.0147 | va_loss=0.3013 | tr_acc=0.9962 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e020/300 | tr_loss=0.0068 | va_loss=0.2114 | tr_acc=0.9985 | va_acc=0.9412 | f1_macro=0.9420\n",
      "[resnet50] e021/300 | tr_loss=0.0103 | va_loss=0.2392 | tr_acc=0.9964 | va_acc=0.9412 | f1_macro=0.9420\n",
      "[resnet50] e022/300 | tr_loss=0.0072 | va_loss=0.2667 | tr_acc=0.9992 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e023/300 | tr_loss=0.0066 | va_loss=0.2830 | tr_acc=0.9987 | va_acc=0.9412 | f1_macro=0.9409\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9429 en la √©poca 24. Guardando checkpoint...\n",
      "[resnet50] e024/300 | tr_loss=0.0074 | va_loss=0.2367 | tr_acc=0.9985 | va_acc=0.9412 | f1_macro=0.9429\n",
      "Early stopping en epoch 24 (mejor f1_macro=0.9420).\n",
      "üìÑ Historial y resumen guardados.\n",
      "üìä Gr√°ficas de entrenamiento guardadas.\n",
      "üìã Tabla LaTeX generada.\n",
      "‚úÖ M√©tricas guardadas en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\metrics_por_carrier.xlsx\n",
      "‚úÖ M√©tricas finales registradas en Excel.\n",
      "Modelo final cargado desde el mejor checkpoint (F1-Macro: 0.9429).\n",
      "[DONE] resnet50 | dur=11.1 min | best_f1_macro=0.9429\n",
      "‚úÖ EXP_3.3_Umb70 Completado.\n",
      "\n",
      "============================================================\n",
      "üß™ INICIANDO: EXP_3.3_Umb90\n",
      "   Fuente: PSEUDO_EXP_3.3_Umb90\n",
      "   Objetivo: Sensibilidad Umbral 0.90\n",
      "============================================================\n",
      "   > Pseudo-etiquetas cargadas: 3081\n",
      "   > Entrenando ResNet50 Student...\n",
      "ThesisHelper inicializado para 'student_trained_with_win_teachersresnet50_EXP_3.3_Umb90'. Artefactos se guardar√°n en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\student_trained_with_win_teachersresnet50_EXP_3.3_Umb90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3864660564.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Nuevo mejor F1-Macro: 0.5429 en la √©poca 1. Guardando checkpoint...\n",
      "[resnet50] e001/300 | tr_loss=0.6394 | va_loss=1.0389 | tr_acc=0.7884 | va_acc=0.5882 | f1_macro=0.5429\n",
      "üöÄ Nuevo mejor F1-Macro: 0.7969 en la √©poca 2. Guardando checkpoint...\n",
      "[resnet50] e002/300 | tr_loss=0.1278 | va_loss=0.6226 | tr_acc=0.9632 | va_acc=0.8039 | f1_macro=0.7969\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8596 en la √©poca 3. Guardando checkpoint...\n",
      "[resnet50] e003/300 | tr_loss=0.0713 | va_loss=0.3615 | tr_acc=0.9796 | va_acc=0.8627 | f1_macro=0.8596\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8653 en la √©poca 4. Guardando checkpoint...\n",
      "[resnet50] e004/300 | tr_loss=0.0555 | va_loss=0.3193 | tr_acc=0.9845 | va_acc=0.8627 | f1_macro=0.8653\n",
      "üöÄ Nuevo mejor F1-Macro: 0.8806 en la √©poca 5. Guardando checkpoint...\n",
      "[resnet50] e005/300 | tr_loss=0.0343 | va_loss=0.3180 | tr_acc=0.9909 | va_acc=0.8824 | f1_macro=0.8806\n",
      "[resnet50] e006/300 | tr_loss=0.0316 | va_loss=0.3258 | tr_acc=0.9912 | va_acc=0.8627 | f1_macro=0.8590\n",
      "üöÄ Nuevo mejor F1-Macro: 0.9615 en la √©poca 7. Guardando checkpoint...\n",
      "[resnet50] e007/300 | tr_loss=0.0274 | va_loss=0.1695 | tr_acc=0.9930 | va_acc=0.9608 | f1_macro=0.9615\n",
      "[resnet50] e008/300 | tr_loss=0.0270 | va_loss=0.2365 | tr_acc=0.9927 | va_acc=0.9020 | f1_macro=0.9018\n",
      "[resnet50] e009/300 | tr_loss=0.0175 | va_loss=0.1796 | tr_acc=0.9963 | va_acc=0.9216 | f1_macro=0.9225\n",
      "[resnet50] e010/300 | tr_loss=0.0170 | va_loss=0.3597 | tr_acc=0.9951 | va_acc=0.8627 | f1_macro=0.8571\n",
      "[resnet50] e011/300 | tr_loss=0.0152 | va_loss=0.2011 | tr_acc=0.9973 | va_acc=0.9216 | f1_macro=0.9187\n",
      "[resnet50] e012/300 | tr_loss=0.0119 | va_loss=0.1501 | tr_acc=0.9960 | va_acc=0.9608 | f1_macro=0.9596\n",
      "[resnet50] e013/300 | tr_loss=0.0072 | va_loss=0.2059 | tr_acc=0.9991 | va_acc=0.9412 | f1_macro=0.9408\n",
      "[resnet50] e014/300 | tr_loss=0.0085 | va_loss=0.2539 | tr_acc=0.9979 | va_acc=0.9020 | f1_macro=0.9014\n",
      "[resnet50] e015/300 | tr_loss=0.0091 | va_loss=0.2022 | tr_acc=0.9982 | va_acc=0.9412 | f1_macro=0.9409\n",
      "[resnet50] e016/300 | tr_loss=0.0067 | va_loss=0.2475 | tr_acc=0.9988 | va_acc=0.8824 | f1_macro=0.8826\n",
      "[resnet50] e017/300 | tr_loss=0.0046 | va_loss=0.1692 | tr_acc=0.9997 | va_acc=0.9020 | f1_macro=0.8991\n",
      "[resnet50] e018/300 | tr_loss=0.0072 | va_loss=0.1368 | tr_acc=0.9982 | va_acc=0.9608 | f1_macro=0.9596\n",
      "[resnet50] e019/300 | tr_loss=0.0084 | va_loss=0.2274 | tr_acc=0.9976 | va_acc=0.9020 | f1_macro=0.9002\n",
      "[resnet50] e020/300 | tr_loss=0.0063 | va_loss=0.2133 | tr_acc=0.9991 | va_acc=0.9020 | f1_macro=0.8991\n",
      "[resnet50] e021/300 | tr_loss=0.0028 | va_loss=0.2064 | tr_acc=1.0000 | va_acc=0.9412 | f1_macro=0.9408\n",
      "[resnet50] e022/300 | tr_loss=0.0045 | va_loss=0.2574 | tr_acc=0.9997 | va_acc=0.9216 | f1_macro=0.9185\n",
      "Early stopping en epoch 22 (mejor f1_macro=0.9615).\n",
      "üìÑ Historial y resumen guardados.\n",
      "üìä Gr√°ficas de entrenamiento guardadas.\n",
      "üìã Tabla LaTeX generada.\n",
      "‚úÖ M√©tricas guardadas en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\metrics_por_carrier.xlsx\n",
      "‚úÖ M√©tricas finales registradas en Excel.\n",
      "Modelo final cargado desde el mejor checkpoint (F1-Macro: 0.9615).\n",
      "[DONE] resnet50 | dur=8.5 min | best_f1_macro=0.9615\n",
      "‚úÖ EXP_3.3_Umb90 Completado.\n",
      "\n",
      "--- TODOS LOS EXPERIMENTOS FINALIZADOS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3864660564.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    }
   ],
   "source": [
    "# --- BUCLE DE EXPERIMENTOS CORREGIDO ---\n",
    "for run in RUN_CONFIG:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üß™ INICIANDO: {run['run_name']}\")\n",
    "    print(f\"   Fuente: {run['source_folder']}\")\n",
    "    print(f\"   Objetivo: {run['desc']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # A. Cargar Pseudo-Etiquetas\n",
    "    pseudo_path = base_exp_dir / run['source_folder']\n",
    "    if not pseudo_path.exists():\n",
    "        print(f\"‚ùå ERROR: No existe {pseudo_path}. Corre el notebook 04 primero.\")\n",
    "        continue\n",
    "        \n",
    "    pseudo_files, pseudo_labels = [], []\n",
    "    for class_path in pseudo_path.glob('*'):\n",
    "        if class_path.is_dir() and class_path.name in cls2idx:\n",
    "            for file_path in class_path.glob(\"*.png\"):\n",
    "                pseudo_files.append(file_path)\n",
    "                pseudo_labels.append(cls2idx[class_path.name])\n",
    "    \n",
    "    print(f\"   > Pseudo-etiquetas cargadas: {len(pseudo_files)}\")\n",
    "    \n",
    "    # B. Dataset Combinado\n",
    "    aug_files = original_train_files + pseudo_files\n",
    "    aug_labels = original_train_labels + pseudo_labels\n",
    "    train_ds = LabeledSpectro(aug_files, aug_labels, transform=weak_aug)\n",
    "    \n",
    "    batch_size = config.TRAIN_PARAMS['resnet50']['BATCH_SIZE']\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # C. Configurar Entrenamiento\n",
    "    current_params = config.TRAIN_PARAMS['resnet50'].copy()\n",
    "    \n",
    "    # --- CORRECCI√ìN CLAVE AQU√ç ---\n",
    "    current_params['MODEL_NAME'] = 'resnet50' # DEBE ser una arquitectura v√°lida para models.py\n",
    "    current_params['EXPERIMENT_SUFFIX'] = f\"_{run['run_name']}\" # El ThesisHelper usar√° esto para la carpeta\n",
    "    # -----------------------------\n",
    "    \n",
    "    # D. Entrenar\n",
    "    print(f\"   > Entrenando ResNet50 Student...\")\n",
    "    train_student(current_params, train_loader, val_loader, num_classes, class_names)\n",
    "    \n",
    "    print(f\"‚úÖ {run['run_name']} Completado.\")\n",
    "\n",
    "print(\"\\n--- TODOS LOS EXPERIMENTOS FINALIZADOS ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7453b9c3-7856-4bbd-958a-c8b1518456af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä GENERANDO TABLA FINAL PARA TESIS (Evaluaci√≥n en Test Set F√≠sico)\n",
      "============================================================\n",
      "üìÇ Leyendo Test Set desde: D:\\Python\\RF_INTERF_4G\\DATA_FOR_TRAINING\\Carrier_C4_9435\\test\n",
      "‚ÑπÔ∏è  Clases detectadas: ['ARM_ANCHO', 'ARM_DELGADO', 'CADI_720', 'CADI_722', 'PIM_OTRO', 'TINA']\n",
      "‚úÖ Total im√°genes encontradas: 45\n",
      "\n",
      "üîç Evaluando Experimento: EXP_3.2_FixMatch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3483582573.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> F1-Macro Test: 0.9761\n",
      "\n",
      "üîç Evaluando Experimento: EXP_3.4_SinExperto...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3483582573.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> F1-Macro Test: 0.9523\n",
      "\n",
      "üîç Evaluando Experimento: EXP_3.3_Umb70...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3483582573.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> F1-Macro Test: 0.9266\n",
      "\n",
      "üîç Evaluando Experimento: EXP_3.3_Umb90...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Zegarra\\AppData\\Local\\Temp\\ipykernel_22848\\3483582573.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> F1-Macro Test: 0.9063\n",
      "\n",
      "=== RESULTADOS FINALES PARA LA TESIS (DATASET TEST OFICIAL) ===\n",
      "          Experimento                       Estrategia  Test_F1_Macro  \\\n",
      "0    EXP_3.2_FixMatch  Baseline SOTA Automatico (0.95)       0.976068   \n",
      "1  EXP_3.4_SinExperto      Ablacion Humana (Auto 0.80)       0.952259   \n",
      "2       EXP_3.3_Umb70         Sensibilidad Umbral 0.70       0.926618   \n",
      "3       EXP_3.3_Umb90         Sensibilidad Umbral 0.90       0.906349   \n",
      "\n",
      "   Test_Accuracy  Test_Recall  \n",
      "0       0.977778     0.976190  \n",
      "1       0.955556     0.952381  \n",
      "2       0.933333     0.928571  \n",
      "3       0.911111     0.907738  \n",
      "\n",
      "‚úÖ Archivo guardado en: D:\\Python\\RF_INTERF_4G\\RESULTADOS\\Carrier_C4_9435\\TABLA_COMPARATIVA_FINAL_TEST_OFICIAL.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELDA FINAL: EVALUACI√ìN POST-ENTRENAMIENTO (Usando carpeta 'test' f√≠sica)\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import models\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"üìä GENERANDO TABLA FINAL PARA TESIS (Evaluaci√≥n en Test Set F√≠sico)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 1. PREPARAR EL TEST SET (Desde tu carpeta f√≠sica)\n",
    "# ---------------------------------------------------------\n",
    "# Basado en tu imagen, la carpeta 'test' est√° al mismo nivel que 'train_val'\n",
    "# Si config.TRAIN_VAL_DIR apunta a '.../Carrier_C4_9435/train_val'\n",
    "# Entonces .parent / 'test' apuntar√° a '.../Carrier_C4_9435/test'\n",
    "TEST_DIR = config.TRAIN_VAL_DIR.parent / \"test\"\n",
    "\n",
    "if not TEST_DIR.exists():\n",
    "    # Fallback por seguridad si la ruta no coincide\n",
    "    print(f\"‚ö†Ô∏è No se detect√≥ autom√°ticamente. Buscando en ruta hardcodeada...\")\n",
    "    TEST_DIR = Path(r\"D:\\Python\\RF_INTERF_4G\\DATA_FOR_TRAINING\\Carrier_C4_9435\\test\")\n",
    "\n",
    "print(f\"üìÇ Leyendo Test Set desde: {TEST_DIR}\")\n",
    "\n",
    "if not TEST_DIR.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå ERROR CR√çTICO: No encuentro la carpeta test en {TEST_DIR}\")\n",
    "\n",
    "# Obtener nombres de clases (Ordenados alfab√©ticamente para coincidir con el entrenamiento)\n",
    "class_names = sorted([p.name for p in TEST_DIR.iterdir() if p.is_dir()])\n",
    "cls2idx = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(f\"‚ÑπÔ∏è  Clases detectadas: {class_names}\")\n",
    "\n",
    "# Cargar archivos de la carpeta test\n",
    "test_files, test_labels = [], []\n",
    "for class_name in class_names:\n",
    "    c_path = TEST_DIR / class_name\n",
    "    if not c_path.exists():\n",
    "        print(f\"‚ö†Ô∏è AVISO: La clase {class_name} no existe en la carpeta test.\")\n",
    "        continue\n",
    "        \n",
    "    files = list(c_path.glob(\"*.png\"))\n",
    "    test_files.extend(files)\n",
    "    test_labels.extend([cls2idx[class_name]] * len(files))\n",
    "\n",
    "print(f\"‚úÖ Total im√°genes encontradas: {len(test_files)}\")\n",
    "\n",
    "# Crear Dataset y Loader\n",
    "# Reutilizamos la clase LabeledSpectro que ya tienes definida arriba\n",
    "test_ds = LabeledSpectro(test_files, test_labels, transform=None)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# 2. BUCLE DE EVALUACI√ìN\n",
    "# ---------------------------------------------------------\n",
    "resultados_tesis = []\n",
    "device = torch.device(config.DEVICE)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Funci√≥n auxiliar de evaluaci√≥n (por si no est√° en memoria)\n",
    "def evaluate_final(model, loader):\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            # Resize obligatorio si es ResNet (asegurar compatibilidad)\n",
    "            xb = torch.nn.functional.interpolate(xb, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "            xb = xb.to(device)\n",
    "            \n",
    "            logits = model(xb)\n",
    "            preds.append(logits.softmax(1).argmax(1).cpu())\n",
    "            gts.append(yb.cpu())\n",
    "            \n",
    "    y_pred = torch.cat(preds).numpy()\n",
    "    y_true = torch.cat(gts).numpy()\n",
    "    \n",
    "    return {\n",
    "        'acc': accuracy_score(y_true, y_pred),\n",
    "        'f1m': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recm': recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "# Iterar sobre los experimentos configurados\n",
    "for run in RUN_CONFIG:\n",
    "    print(f\"\\nüîç Evaluando Experimento: {run['run_name']}...\")\n",
    "    \n",
    "    # Construir ruta del modelo guardado\n",
    "    # Nombre de carpeta: student_trained_with_win_teachersresnet50_{SUFFIX}\n",
    "    folder_name = f\"student_trained_with_win_teachersresnet50_{run['run_name']}\"\n",
    "    model_path = config.RESULTS_DIR / folder_name / \"best_model.pth\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"‚ùå ERROR: No encuentro el modelo en {model_path}\")\n",
    "        # Intentar buscar sin el prefijo por si acaso\n",
    "        continue\n",
    "        \n",
    "    # Cargar Arquitectura\n",
    "    model = models.make_model('resnet50', len(class_names), resnet_use_pretrain=False)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    \n",
    "    # Evaluar\n",
    "    metrics = evaluate_final(model, test_loader)\n",
    "    \n",
    "    print(f\"   -> F1-Macro Test: {metrics['f1m']:.4f}\")\n",
    "    \n",
    "    resultados_tesis.append({\n",
    "        \"Experimento\": run['run_name'],\n",
    "        \"Estrategia\": run['desc'],\n",
    "        \"Test_F1_Macro\": metrics['f1m'],\n",
    "        \"Test_Accuracy\": metrics['acc'],\n",
    "        \"Test_Recall\": metrics['recm']\n",
    "    })\n",
    "\n",
    "# 3. GUARDAR CSV FINAL\n",
    "# ---------------------------------------------------------\n",
    "df_final = pd.DataFrame(resultados_tesis)\n",
    "print(\"\\n=== RESULTADOS FINALES PARA LA TESIS (DATASET TEST OFICIAL) ===\")\n",
    "print(df_final)\n",
    "\n",
    "output_csv = config.RESULTS_DIR / \"TABLA_COMPARATIVA_FINAL_TEST_OFICIAL.csv\"\n",
    "df_final.to_csv(output_csv, index=False)\n",
    "print(f\"\\n‚úÖ Archivo guardado en: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf2ee6-1486-4902-8c3c-f3e2d207a71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
