{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ac76d78-4051-4aa2-a144-fe4ace91a7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INICIANDO BUCLE DE EXPERIMENTO 3.1: BASELINES CLÁSICOS\n",
      "Ruta Base: D:\\Python\\RF_INTERF_4G\\DATA\\experimento_baselines\n",
      "============================================================\n",
      "\n",
      "--- Procesando Carrier: Carrier_C1_675 ---\n",
      "  Cargando datos desde: train_set_70\n",
      "  Clases detectadas: ['ARM_ANCHO', 'ARM_DELGADO', 'PIM_OTRO', 'TINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cargando datos desde: test_set_15\n",
      "  Clases detectadas: ['ARM_ANCHO', 'ARM_DELGADO', 'PIM_OTRO', 'TINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estandarizando características (StandardScaler)...\n",
      "  Entrenando Random Forest...\n",
      "  F1-Macro (RF): 0.7647\n",
      "  Entrenando SVM (Kernel RBF)...\n",
      "  F1-Macro (SVM): 0.7639\n",
      "\n",
      "--- Procesando Carrier: Carrier_C2_2825 ---\n",
      "  Cargando datos desde: train_set_70\n",
      "  Clases detectadas: ['ARM_DELGADO', 'MW', 'PIM_OTRO', 'TINA', 'WIFI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cargando datos desde: test_set_15\n",
      "  Clases detectadas: ['ARM_DELGADO', 'MW', 'PIM_OTRO', 'TINA', 'WIFI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estandarizando características (StandardScaler)...\n",
      "  Entrenando Random Forest...\n",
      "  F1-Macro (RF): 0.6130\n",
      "  Entrenando SVM (Kernel RBF)...\n",
      "  F1-Macro (SVM): 0.7405\n",
      "\n",
      "--- Procesando Carrier: Carrier_C3_2975 ---\n",
      "  Cargando datos desde: train_set_70\n",
      "  Clases detectadas: ['ARM_DELGADO', 'MW', 'PIM_OTRO', 'TINA', 'WIFI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cargando datos desde: test_set_15\n",
      "  Clases detectadas: ['ARM_DELGADO', 'MW', 'PIM_OTRO', 'TINA', 'WIFI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estandarizando características (StandardScaler)...\n",
      "  Entrenando Random Forest...\n",
      "  F1-Macro (RF): 0.8143\n",
      "  Entrenando SVM (Kernel RBF)...\n",
      "  F1-Macro (SVM): 0.7879\n",
      "\n",
      "--- Procesando Carrier: Carrier_C4_9435 ---\n",
      "  Cargando datos desde: train_set_70\n",
      "  Clases detectadas: ['ARM_ANCHO', 'ARM_DELGADO', 'CADI_720', 'CADI_722', 'PIM_OTRO', 'TINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cargando datos desde: test_set_15\n",
      "  Clases detectadas: ['ARM_ANCHO', 'ARM_DELGADO', 'CADI_720', 'CADI_722', 'PIM_OTRO', 'TINA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estandarizando características (StandardScaler)...\n",
      "  Entrenando Random Forest...\n",
      "  F1-Macro (RF): 0.7878\n",
      "  Entrenando SVM (Kernel RBF)...\n",
      "  F1-Macro (SVM): 0.8090\n",
      "\n",
      "============================================================\n",
      "EXPERIMENTOS COMPLETADOS. GENERANDO TABLA 10...\n",
      "============================================================\n",
      "| Modelo | C1_675 | C2_2825 | C3_2975 | C4_9435 | Promedio |\n",
      "| :--- | :---: | :---: | :---: | :---: | :---: |\n",
      "| SVM (kernel RBF) | 0.76 | 0.74 | 0.79 | 0.81 | **0.78** |\n",
      "| Random Forest (100 est.) | 0.76 | 0.61 | 0.81 | 0.79 | **0.74** |\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# --- CONFIGURACIÓN DEL EXPERIMENTO ---\n",
    "\n",
    "# Semilla para reproducibilidad (¡Importante para Tesis!)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# =============================================================================\n",
    "# RUTAS\n",
    "# =============================================================================\n",
    "# 1. RUTA_BASE: El directorio que contiene TODAS las carpetas de Carriers\n",
    "#    (Basado en tu imagen: D:\\Python\\RF_INTERF_4G\\DATA\\experimento_baselines)\n",
    "RUTA_BASE = Path(r\"D:\\Python\\RF_INTERF_4G\\DATA\\experimento_baselines\")\n",
    "\n",
    "# 2. NOMBRES DE CARRIERS: Las carpetas que el \"for\" debe buscar\n",
    "CARRIER_NAMES = [\n",
    "    \"Carrier_C1_675\",\n",
    "    \"Carrier_C2_2825\",\n",
    "    \"Carrier_C3_2975\",\n",
    "    \"Carrier_C4_9435\"\n",
    "]\n",
    "\n",
    "# 3. NOMBRES DE SUB-CARPETAS: Cómo se llaman tus carpetas de train/test\n",
    "#    (Basado en tu Figura 7)\n",
    "TRAIN_FOLDER_NAME = \"train_set_70\"\n",
    "TEST_FOLDER_NAME = \"test_set_15\"\n",
    "\n",
    "# Tamaño de imagen (100x100)\n",
    "IMAGE_SIZE = (100, 100) \n",
    "\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def load_and_flatten_images(base_dir: Path) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Carga imágenes, las convierte a escala de grises (monocanal)\n",
    "    y las aplana a vectores 1D.\n",
    "    \"\"\"\n",
    "    X_data, y_data = [], []\n",
    "    \n",
    "    if not base_dir.exists():\n",
    "        print(f\"  [ERROR] La ruta no existe: {base_dir}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    # Obtener clases, ignorando la carpeta SIN_CLASIFICAR\n",
    "    classes = sorted([\n",
    "        d.name for d in base_dir.iterdir() \n",
    "        if d.is_dir() and d.name.upper() != \"SIN_CLASIFICAR\"\n",
    "    ])\n",
    "    \n",
    "    if not classes:\n",
    "        print(f\"  [ERROR] No se encontraron carpetas de clases en {base_dir}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    print(f\"  Cargando datos desde: {base_dir.name}\")\n",
    "    print(f\"  Clases detectadas: {classes}\")\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = base_dir / class_name\n",
    "        image_paths = list(class_dir.glob('*.png')) + \\\n",
    "                      list(class_dir.glob('*.jpg')) + \\\n",
    "                      list(class_dir.glob('*.jpeg'))\n",
    "        \n",
    "        if not image_paths:\n",
    "            print(f\"  [Advertencia] Clase '{class_name}' está vacía.\")\n",
    "            continue\n",
    "\n",
    "        for img_path in tqdm(image_paths, desc=f\"    Leyendo {class_name}\", leave=False, ncols=80):\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    # 1. Convertir a Escala de Grises ('L') (Monocanal)\n",
    "                    img = img.convert('L')\n",
    "                    # 2. Redimensionar a 100x100\n",
    "                    img = img.resize(IMAGE_SIZE)\n",
    "                    # 3. Aplanar de (100, 100) -> (10000,)\n",
    "                    img_vector = np.asarray(img).flatten()\n",
    "                    \n",
    "                    X_data.append(img_vector)\n",
    "                    y_data.append(class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"  Error leyendo {img_path.name}: {e}\")\n",
    "\n",
    "    return np.array(X_data), np.array(y_data), classes\n",
    "\n",
    "def run_single_carrier(train_dir: Path, test_dir: Path) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Ejecuta el experimento SVM y RF para un solo carrier.\n",
    "    Devuelve un diccionario con los F1-Scores Macro.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Cargar Datos\n",
    "    X_train, y_train, _ = load_and_flatten_images(train_dir)\n",
    "    X_test, y_test, _ = load_and_flatten_images(test_dir)\n",
    "    \n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(\"  [ERROR] No hay datos de train o test. Saltando este carrier.\")\n",
    "        return {\"rf_f1\": 0.0, \"svm_f1\": 0.0}\n",
    "\n",
    "    # 2. Preprocesamiento (Escalado)\n",
    "    print(\"  Estandarizando características (StandardScaler)...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Modelo A: Random Forest\n",
    "    print(\"  Entrenando Random Forest...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    y_pred_rf = rf.predict(X_test_scaled)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='macro', zero_division=0)\n",
    "    print(f\"  F1-Macro (RF): {f1_rf:.4f}\")\n",
    "\n",
    "    # 4. Modelo B: SVM (RBF)\n",
    "    print(\"  Entrenando SVM (Kernel RBF)...\")\n",
    "    svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=RANDOM_STATE)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred_svm = svm.predict(X_test_scaled)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='macro', zero_division=0)\n",
    "    print(f\"  F1-Macro (SVM): {f1_svm:.4f}\")\n",
    "\n",
    "    return {\"rf_f1\": f1_rf, \"svm_f1\": f1_svm}\n",
    "\n",
    "def main_experiment_loop():\n",
    "    \"\"\"\n",
    "    Función principal que itera (\"for\") sobre cada carpeta de carrier,\n",
    "    ejecuta los experimentos y genera la tabla final.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"INICIANDO BUCLE DE EXPERIMENTO 3.1: BASELINES CLÁSICOS\")\n",
    "    print(f\"Ruta Base: {RUTA_BASE}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Diccionario para almacenar los resultados\n",
    "    all_results = {\n",
    "        \"SVM (kernel RBF)\": [],\n",
    "        \"Random Forest (100 est.)\": []\n",
    "    }\n",
    "    \n",
    "    # El \"for\" que solicitaste\n",
    "    for carrier_name in CARRIER_NAMES:\n",
    "        print(f\"\\n--- Procesando Carrier: {carrier_name} ---\")\n",
    "        \n",
    "        train_path = RUTA_BASE / carrier_name / TRAIN_FOLDER_NAME\n",
    "        test_path = RUTA_BASE / carrier_name / TEST_FOLDER_NAME\n",
    "        \n",
    "        # Ejecutar el experimento para este carrier\n",
    "        scores = run_single_carrier(train_path, test_path)\n",
    "        \n",
    "        # Guardar los resultados\n",
    "        all_results[\"SVM (kernel RBF)\"].append(scores[\"svm_f1\"])\n",
    "        all_results[\"Random Forest (100 est.)\"].append(scores[\"rf_f1\"])\n",
    "\n",
    "    # --- Generación de la Tabla Final ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXPERIMENTOS COMPLETADOS. GENERANDO TABLA 10...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Calcular Promedios\n",
    "    avg_svm = np.mean(all_results[\"SVM (kernel RBF)\"])\n",
    "    avg_rf = np.mean(all_results[\"Random Forest (100 est.)\"])\n",
    "    \n",
    "    # Imprimir encabezado de la tabla (formato Markdown)\n",
    "    header = \"| Modelo |\"\n",
    "    divider = \"| :--- |\"\n",
    "    for name in CARRIER_NAMES:\n",
    "        # Extraer solo el número (ej. C1_675)\n",
    "        short_name = name.split('_', 1)[1] \n",
    "        header += f\" {short_name} |\"\n",
    "        divider += \" :---: |\"\n",
    "    header += \" Promedio |\"\n",
    "    divider += \" :---: |\"\n",
    "    print(header)\n",
    "    print(divider)\n",
    "\n",
    "    # Imprimir fila de SVM\n",
    "    svm_scores = all_results[\"SVM (kernel RBF)\"]\n",
    "    svm_row = f\"| SVM (kernel RBF) |\"\n",
    "    for score in svm_scores:\n",
    "        svm_row += f\" {score:.2f} |\"\n",
    "    svm_row += f\" **{avg_svm:.2f}** |\"\n",
    "    print(svm_row)\n",
    "\n",
    "    # Imprimir fila de Random Forest\n",
    "    rf_scores = all_results[\"Random Forest (100 est.)\"]\n",
    "    rf_row = f\"| Random Forest (100 est.) |\"\n",
    "    for score in rf_scores:\n",
    "        rf_row += f\" {score:.2f} |\"\n",
    "    rf_row += f\" **{avg_rf:.2f}** |\"\n",
    "    print(rf_row)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_experiment_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f68f26c-f131-4c8f-8fdd-820434e64015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7363d-9887-4220-8136-e66918ab15f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
