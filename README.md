# LTE Interference Classification via Semi-Supervised Teacherâ€“Student Approach with CNN and ResNet

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![Framework](https://img.shields.io/badge/PyTorch%20%7C%20TensorFlow-orange)](https://pytorch.org/)

This repository contains the official implementation, experimental notebooks, and results for the paper: **"LTE Interference Classification via Semi-Supervised Teacherâ€“Student Approach with CNN and ResNet"**.

**Authors:** Jorge Luis Zegarra Guardamino, Percy Maldonado-Quispe.  
*School of Computer Science, National University of San AgustÃ­n de Arequipa (UNSA).*

---

## ğŸ“ Abstract

This study proposes a pragmatic semi-supervised pipeline for classifying interference in the LTE uplink, designed to optimize expert time through a **Human-in-the-Loop (HITL)** scheme.

Unlike fully automated methods that risk error propagation in critical domains, our approach utilizes *Teacher* models to generate pseudo-labels, where only those with high confidence ($\ge 80\%$) are submitted for rapid expert validation.

**Key Findings:**
* There is a direct relationship between data density and the optimal architecture.
* **ResNet50** maximizes precision in carriers with high spectral complexity.
* **ResNet18** offers superior generalization in scenarios with sample scarcity.

## ğŸ“Š Key Results

The proposed approach successfully balances computational cost with operational safety:

| Scenario | Metric | Result |
| :--- | :--- | :--- |
| **Medium Density** | Macro F1-Score | **0.946** |
| **Medium Density** | Accuracy | **94.74%** |
| **High Volume** | F1-Score | 0.928 |

---

## ğŸ“‚ Repository Structure

Based on the official implementation layout:

```text
â”œâ”€â”€ MUESTRAS_ini/           # Original Raw Data (Source)
â”‚   â”œâ”€â”€ Carrier_C1_675/     # Data per carrier
â”‚   â”‚   â”œâ”€â”€ ARM_ANCHO/      # Class folders
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ DATA_FOR_TRAINING/      # Processed Data (Split Train/Test)
â”‚   â””â”€â”€ Carrier_X/
â”‚       â”œâ”€â”€ train_val/      # Training + Validation set (80%)
â”‚       â””â”€â”€ test/           # Held-out Test set (20%)
â”œâ”€â”€ RESULTADOS/             # Experiment Outputs
â”‚   â”œâ”€â”€ BENCHMARK/          # Resource usage stats
â”‚   â””â”€â”€ Carrier_X/          # Model checkpoints, Confusion Matrices, Logs
â”œâ”€â”€ 00_data_prep.py         # Data splitting script
â”œâ”€â”€ 01_train_teachers.ipynb # Teacher model training
â”œâ”€â”€ 02_pseudo_labeling.ipynb# Pseudo-label generation (HITL)
â”œâ”€â”€ 03_train_student.ipynb  # Student model training (Augmented)
â”œâ”€â”€ 04_final_eval.py        # Official evaluation on Test Set
â”œâ”€â”€ 05_benchmarking.py      # Resource benchmarking (FPS/Params)
â”œâ”€â”€ 06_baseline_prep.ipynb  # Data prep for SVM/RF
â”œâ”€â”€ 07_baselines.ipynb      # Classical ML Baselines (SVM/RF)
â”œâ”€â”€ 08_run_ablation.ipynb   # Ablation studies execution
â”œâ”€â”€ 09_gen_ablation_data.ipynb # Data generation for ablations
â”œâ”€â”€ 10_data_stats.ipynb     # Data distribution analysis
â”œâ”€â”€ config.py               # Global configuration and paths
â”œâ”€â”€ models.py               # CNN & ResNet architectures
â”œâ”€â”€ utils.py                # Helper functions
â””â”€â”€ requirements.txt        # Dependencies
