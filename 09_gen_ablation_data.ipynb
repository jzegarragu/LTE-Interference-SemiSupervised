{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10f0b9-59ec-4be3-a362-b376619fba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EXPERIMENT DATA GENERATION SCRIPT\n",
    "# ==============================================================================\n",
    "# This script generates isolated datasets to support ablation studies and \n",
    "# comparative analysis (e.g., Threshold Sensitivity, FixMatch baseline).\n",
    "# It does NOT modify the official pseudo-label dataset.\n",
    "\n",
    "import torch\n",
    "import shutil\n",
    "import models\n",
    "import utils\n",
    "import config\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- EXPERIMENTAL CONFIGURATION ---\n",
    "TEACHER_ARCH = \"resnet50\"  # Winning teacher architecture used for generation\n",
    "DEVICE = torch.device(config.DEVICE)\n",
    "\n",
    "# Relative Paths\n",
    "BASE_RESULTS_DIR = config.ARTIFACTS_DIR\n",
    "UNLABELED_DIR = config.UNLABELED_DIR\n",
    "CLASS_NAMES = sorted([p.name for p in config.TRAIN_VAL_DIR.iterdir() if p.is_dir()])\n",
    "\n",
    "# --- EXPERIMENTS DEFINITION ---\n",
    "# Dictionary defining the experiments to generate.\n",
    "# Key: Experiment Name (Folder Name)\n",
    "# Value: Confidence Threshold for Pseudo-Labeling\n",
    "EXPERIMENTS_DICT = {\n",
    "    # Experiment 3.3: Threshold Ablation Study\n",
    "    # Objective: Validate the choice of 0.80 by comparing against looser (0.70) and stricter (0.90) thresholds.\n",
    "    \"PSEUDO_EXP_3.3_Umb70\": 0.70,\n",
    "    \"PSEUDO_EXP_3.3_Umb90\": 0.90,\n",
    "    \n",
    "    # Experiment 3.4: Automated Baseline (No Human Verification)\n",
    "    # Objective: Assess the performance of raw pseudo-labels at the chosen threshold (0.80).\n",
    "    \"PSEUDO_EXP_3.4_Auto80\": 0.80, \n",
    "\n",
    "    # Experiment 3.2: High-Confidence Baseline (Simulating FixMatch)\n",
    "    # Objective: Compare against a fully automated SOTA approach which typically uses high thresholds (0.95).\n",
    "    \"PSEUDO_EXP_3.2_FixMatch95\": 0.95\n",
    "}\n",
    "\n",
    "print(f\"--- STARTING EXPERIMENTAL DATA GENERATION ---\")\n",
    "print(f\"Scenario: {config.CURRENT_CARRIER}\")\n",
    "print(f\"Base Teacher: {TEACHER_ARCH}\")\n",
    "print(f\"Experiments: {list(EXPERIMENTS_DICT.keys())}\")\n",
    "\n",
    "# 1. LOAD TEACHER MODEL (Inference Mode)\n",
    "def find_best_teacher_checkpoint(model_arch):\n",
    "    \"\"\"Locates the best checkpoint for the specified teacher architecture.\"\"\"\n",
    "    candidates = sorted([d for d in BASE_RESULTS_DIR.iterdir() if f\"teacher_{model_arch}\" in d.name])\n",
    "    if not candidates: \n",
    "        raise FileNotFoundError(f\"Teacher checkpoint for {model_arch} not found.\")\n",
    "    return candidates[-1] / \"best_model.pth\"\n",
    "\n",
    "ckpt_path = find_best_teacher_checkpoint(TEACHER_ARCH)\n",
    "print(f\"[INFO] Loading Teacher Weights: {ckpt_path.name}\")\n",
    "\n",
    "model = models.make_model(TEACHER_ARCH, len(CLASS_NAMES), resnet_use_pretrain=False)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE, weights_only=True))\n",
    "except TypeError:\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 2. SETUP ISOLATED FOLDER STRUCTURE\n",
    "# Creates a separate root folder to avoid contamination with the official dataset\n",
    "root_exp_dir = BASE_RESULTS_DIR / \"ABLATION_EXPERIMENTS\"\n",
    "\n",
    "if root_exp_dir.exists():\n",
    "    print(\"[INFO] Cleaning previous experiment data...\")\n",
    "    shutil.rmtree(root_exp_dir)\n",
    "root_exp_dir.mkdir()\n",
    "\n",
    "# Create subdirectories for each experiment and class\n",
    "for exp_name in EXPERIMENTS_DICT.keys():\n",
    "    exp_path = root_exp_dir / exp_name\n",
    "    exp_path.mkdir()\n",
    "    for cname in CLASS_NAMES:\n",
    "        (exp_path / cname).mkdir()\n",
    "    print(f\" > Created directory: {exp_path.name}\")\n",
    "\n",
    "# 3. INFERENCE AND DISTRIBUTION LOOP\n",
    "unlabeled_images = list(UNLABELED_DIR.glob(\"*.png\"))\n",
    "print(f\"\\n[INFO] Processing {len(unlabeled_images)} unlabeled images...\")\n",
    "\n",
    "stats = {k: 0 for k in EXPERIMENTS_DICT.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_path in tqdm(unlabeled_images, desc=\"Distributing Data\"):\n",
    "        try:\n",
    "            # Preprocessing\n",
    "            img_tensor = utils.load_png_gray(img_path)\n",
    "            \n",
    "            # Mandatory resize for ResNet\n",
    "            img_tensor = torch.nn.functional.interpolate(\n",
    "                img_tensor.unsqueeze(0), size=(224, 224), mode=\"bilinear\", align_corners=False\n",
    "            ).squeeze(0)\n",
    "            \n",
    "            img_tensor = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "            # Teacher Prediction\n",
    "            logits = model(img_tensor)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            max_prob, pred_idx = torch.max(probs, dim=1)\n",
    "            \n",
    "            confidence = max_prob.item()\n",
    "            pred_class = CLASS_NAMES[pred_idx.item()]\n",
    "\n",
    "            # DISTRIBUTION LOGIC:\n",
    "            # A single image can belong to multiple experiments if it meets their respective thresholds.\n",
    "            # Each experiment folder is an isolated universe.\n",
    "            for exp_name, threshold in EXPERIMENTS_DICT.items():\n",
    "                if confidence >= threshold:\n",
    "                    # Copy image to the specific experiment folder\n",
    "                    dest = root_exp_dir / exp_name / pred_class / img_path.name\n",
    "                    shutil.copy(str(img_path), str(dest))\n",
    "                    stats[exp_name] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Error processing {img_path.name}: {e}\")\n",
    "\n",
    "print(\"\\n--- GENERATION SUMMARY ---\")\n",
    "for exp_name, count in stats.items():\n",
    "    print(f\"[{exp_name}] (Threshold >={EXPERIMENTS_DICT[exp_name]}): {count} images generated.\")\n",
    "\n",
    "print(f\"\\n[DONE] Experimental datasets created at: {root_exp_dir}\")\n",
    "print(\"[NOTE] The official 'pseudo_labels' directory remains unchanged.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
